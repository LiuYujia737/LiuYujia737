{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "\n",
    "def load_tsv_data(file_path):\n",
    "    data = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) >= 2:\n",
    "                review = parts[0]\n",
    "                features = parts[1:]\n",
    "                for feature in features:\n",
    "                    feature_parts = feature.split()\n",
    "                    if len(feature_parts) >= 4:\n",
    "                        aspect_term_indices = feature_parts[0].split(',')\n",
    "                        sentiment = feature_parts[2]\n",
    "                        sentiment_term_indices = feature_parts[3].split(',')\n",
    "                        \n",
    "                        if aspect_term_indices[0] == '-1':\n",
    "                            aspect_term = 'NULL'\n",
    "                        else:\n",
    "                            start, end = int(aspect_term_indices[0]), int(aspect_term_indices[1])\n",
    "                            aspect_term = ' '.join(review.split()[start:end])\n",
    "                        \n",
    "                        if sentiment_term_indices[0] == '-1':\n",
    "                            sentiment_term = 'NULL'\n",
    "                        else:\n",
    "                            start, end = int(sentiment_term_indices[0]), int(sentiment_term_indices[1])\n",
    "                            sentiment_term = ' '.join(review.split()[start:end])\n",
    "                        \n",
    "                        data.append({\n",
    "                            'review': review,\n",
    "                            'aspect_term': aspect_term,\n",
    "                            'sentiment_term': sentiment_term,\n",
    "                            'sentiment': sentiment\n",
    "                        })\n",
    "            else:\n",
    "                print(f\"Skipping malformed line: {line.strip()}\")\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def train_and_tune_model(X_train, y_train, X_dev, y_dev):\n",
    "    try:\n",
    "        # define the parameter grid\n",
    "        param_grid = {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'kernel': ['linear', 'rbf'],\n",
    "            'gamma': ['scale', 'auto', 0.1, 1]\n",
    "        }\n",
    "        \n",
    "        # perform grid search with cross-validation\n",
    "        grid_search = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # get the best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        \n",
    "        # evaluate the best model on the dev\n",
    "        dev_accuracy = best_model.score(X_dev, y_dev)\n",
    "        print(f\"Best model parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Development set accuracy: {dev_accuracy}\")\n",
    "        \n",
    "        return best_model\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model training and tuning: {e}\")\n",
    "        return None\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    try:\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        return accuracy, report\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model evaluation: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running baseline experiment...\n",
      "\n",
      "Extracting features...\n",
      "Encoding labels...\n",
      "Training and tuning model...\n",
      "Best model parameters: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Development set accuracy: 0.8659003831417624\n",
      "Evaluating model...\n",
      "\n",
      "Baseline Experiment Results:\n",
      "Accuracy: 0.8417030567685589\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.77      0.72       205\n",
      "           1       0.00      0.00      0.00        44\n",
      "           2       0.90      0.92      0.91       667\n",
      "\n",
      "    accuracy                           0.84       916\n",
      "   macro avg       0.52      0.56      0.54       916\n",
      "weighted avg       0.81      0.84      0.82       916\n",
      "\n",
      "\n",
      "Baseline Experiments completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Program Files\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Program Files\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "def extract_features1(reviews, model, tokenizer):\n",
    "    features = []\n",
    "    for text in reviews:\n",
    "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        features.append(outputs.last_hidden_state.mean(dim=1).squeeze().numpy())\n",
    "    return np.array(features)\n",
    "\n",
    "def baseline_experiment1(train_data, dev_data, test_data, model, tokenizer):\n",
    "    \n",
    "    print(\"\\nExtracting features...\")\n",
    "    X_train = extract_features1(train_data['review'], model, tokenizer)\n",
    "    X_dev = extract_features1(dev_data['review'], model, tokenizer)\n",
    "    X_test = extract_features1(test_data['review'], model, tokenizer)\n",
    "    \n",
    "    print(\"Encoding labels...\")\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_data['sentiment'].tolist() + dev_data['sentiment'].tolist() + test_data['sentiment'].tolist())\n",
    "    y_train = le.transform(train_data['sentiment'])\n",
    "    y_dev = le.transform(dev_data['sentiment'])\n",
    "    y_test = le.transform(test_data['sentiment'])\n",
    "    \n",
    "    print(\"Training and tuning model...\")\n",
    "    best_classifier = train_and_tune_model(X_train, y_train, X_dev, y_dev)\n",
    "    \n",
    "    print(\"Evaluating model...\")\n",
    "    accuracy, report = evaluate_model(best_classifier, X_test, y_test)\n",
    "    \n",
    "    return best_classifier, le, accuracy, report\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    bert_model = BertModel.from_pretrained(r'D:\\AIProject\\Bert\\model')\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained(r'D:\\AIProject\\Bert\\tokenizer')\n",
    "\n",
    "    # restuarant\n",
    "    rest_train_data = load_tsv_data(r'D:\\AIProject\\data\\restaurant\\rest16_quad_train.tsv')\n",
    "    rest_test_data = load_tsv_data(r'D:\\AIProject\\data\\restaurant\\rest16_quad_test.tsv')\n",
    "    rest_dev_data = load_tsv_data(r'D:\\AIProject\\data\\restaurant\\rest16_quad_dev.tsv')\n",
    "    \n",
    "    print(\"\\nRunning baseline experiment...\")\n",
    "    baseline_classifier, baseline_le, baseline_accuracy1, baseline_report1 = baseline_experiment1(rest_train_data, rest_dev_data, rest_test_data, bert_model, bert_tokenizer)\n",
    "    \n",
    "    print(\"\\nBaseline Experiment Results:\")\n",
    "    print(f\"Accuracy: {baseline_accuracy1}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(baseline_report1)\n",
    "\n",
    "    print(\"\\nBaseline Experiments completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reviews, aspect_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running baseline experiment...\n",
      "\n",
      "Extracting features...\n",
      "Encoding labels...\n",
      "Training and tuning model...\n",
      "Best model parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Development set accuracy: 0.8582375478927203\n",
      "Evaluating model...\n",
      "\n",
      "Baseline Experiment Results:\n",
      "Accuracy: 0.8417030567685589\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73       205\n",
      "           1       0.00      0.00      0.00        44\n",
      "           2       0.90      0.91      0.91       667\n",
      "\n",
      "    accuracy                           0.84       916\n",
      "   macro avg       0.52      0.57      0.54       916\n",
      "weighted avg       0.81      0.84      0.82       916\n",
      "\n",
      "\n",
      "Baseline Experiments completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Program Files\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Program Files\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "def extract_features2(reviews, aspect_terms, model, tokenizer):\n",
    "    features = []\n",
    "    for review, aspect_term in zip(reviews, aspect_terms):\n",
    "        inputs = tokenizer(review, aspect_term, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        features.append(outputs.last_hidden_state.mean(dim=1).squeeze().numpy())\n",
    "    return np.array(features)\n",
    "\n",
    "def baseline_experiment2(train_data, dev_data, test_data, model, tokenizer):\n",
    "    \n",
    "    print(\"\\nExtracting features...\")\n",
    "    X_train = extract_features2(train_data['review'], train_data['aspect_term'], model, tokenizer)\n",
    "    X_dev = extract_features2(dev_data['review'], dev_data['aspect_term'], model, tokenizer)\n",
    "    X_test = extract_features2(test_data['review'], test_data['aspect_term'], model, tokenizer)\n",
    "    \n",
    "    print(\"Encoding labels...\")\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_data['sentiment'].tolist() + dev_data['sentiment'].tolist() + test_data['sentiment'].tolist())\n",
    "    y_train = le.transform(train_data['sentiment'])\n",
    "    y_dev = le.transform(dev_data['sentiment'])\n",
    "    y_test = le.transform(test_data['sentiment'])\n",
    "    \n",
    "    print(\"Training and tuning model...\")\n",
    "    best_classifier = train_and_tune_model(X_train, y_train, X_dev, y_dev)\n",
    "    \n",
    "    print(\"Evaluating model...\")\n",
    "    accuracy, report = evaluate_model(best_classifier, X_test, y_test)\n",
    "    \n",
    "    return best_classifier, le, accuracy, report\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    bert_model = BertModel.from_pretrained(r'D:\\AIProject\\Bert\\model')\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained(r'D:\\AIProject\\Bert\\tokenizer')\n",
    "\n",
    "    # restuarant\n",
    "    rest_train_data = load_tsv_data(r'D:\\AIProject\\data\\restaurant\\rest16_quad_train.tsv')\n",
    "    rest_test_data = load_tsv_data(r'D:\\AIProject\\data\\restaurant\\rest16_quad_test.tsv')\n",
    "    rest_dev_data = load_tsv_data(r'D:\\AIProject\\data\\restaurant\\rest16_quad_dev.tsv')\n",
    "    \n",
    "    print(\"\\nRunning baseline experiment...\")\n",
    "    baseline_classifier, baseline_le, baseline_accuracy2, baseline_report2 = baseline_experiment2(rest_train_data, rest_dev_data, rest_test_data, bert_model, bert_tokenizer)\n",
    "    \n",
    "    print(\"\\nBaseline Experiment Results:\")\n",
    "    print(f\"Accuracy: {baseline_accuracy2}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(baseline_report2)\n",
    "\n",
    "    print(\"\\nBaseline Experiments completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reviews, aspect_terms, sentiment_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running baseline experiment...\n",
      "\n",
      "Extracting features...\n",
      "Encoding labels...\n",
      "Training and tuning model...\n",
      "Best model parameters: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Development set accuracy: 0.8582375478927203\n",
      "Evaluating model...\n",
      "\n",
      "Baseline Experiment Results:\n",
      "Accuracy: 0.8482532751091703\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.83      0.74       205\n",
      "           1       0.56      0.11      0.19        44\n",
      "           2       0.92      0.90      0.91       667\n",
      "\n",
      "    accuracy                           0.85       916\n",
      "   macro avg       0.71      0.62      0.61       916\n",
      "weighted avg       0.85      0.85      0.84       916\n",
      "\n",
      "\n",
      "Baseline Experiments completed.\n"
     ]
    }
   ],
   "source": [
    "def extract_features(reviews, aspect_terms, sentiment_terms, model, tokenizer):\n",
    "    features = []\n",
    "    for review, aspect_term, sentiment_term in zip(reviews, aspect_terms, sentiment_terms):\n",
    "        # combine review, aspect term, and sentiment term into a single text\n",
    "        combined_text = f\"{review} [SEP] {aspect_term} [SEP] {sentiment_term}\"\n",
    "        \n",
    "        inputs = tokenizer(combined_text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        features.append(outputs.last_hidden_state.mean(dim=1).squeeze().numpy())\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "def baseline_experiment(train_data, dev_data, test_data, model, tokenizer):\n",
    "    \n",
    "    print(\"\\nExtracting features...\")\n",
    "    X_train = extract_features(train_data['review'], train_data['aspect_term'], train_data['sentiment_term'], model, tokenizer)\n",
    "    X_dev = extract_features(dev_data['review'], dev_data['aspect_term'], dev_data['sentiment_term'], model, tokenizer)\n",
    "    X_test = extract_features(test_data['review'], test_data['aspect_term'], test_data['sentiment_term'], model, tokenizer)\n",
    "    \n",
    "    print(\"Encoding labels...\")\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_data['sentiment'].tolist() + dev_data['sentiment'].tolist() + test_data['sentiment'].tolist())\n",
    "    y_train = le.transform(train_data['sentiment'])\n",
    "    y_dev = le.transform(dev_data['sentiment'])\n",
    "    y_test = le.transform(test_data['sentiment'])\n",
    "    \n",
    "    print(\"Training and tuning model...\")\n",
    "    best_classifier = train_and_tune_model(X_train, y_train, X_dev, y_dev)\n",
    "    \n",
    "    print(\"Evaluating model...\")\n",
    "    accuracy, report = evaluate_model(best_classifier, X_test, y_test)\n",
    "    \n",
    "    return best_classifier, le, accuracy, report\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    bert_model = BertModel.from_pretrained(r'D:\\AIProject\\Bert\\model')\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained(r'D:\\AIProject\\Bert\\tokenizer')\n",
    "\n",
    "    # restuarant\n",
    "    rest_train_data = load_tsv_data(r'D:\\AIProject\\data\\restaurant\\rest16_quad_train.tsv')\n",
    "    rest_test_data = load_tsv_data(r'D:\\AIProject\\data\\restaurant\\rest16_quad_test.tsv')\n",
    "    rest_dev_data = load_tsv_data(r'D:\\AIProject\\data\\restaurant\\rest16_quad_dev.tsv')\n",
    "    \n",
    "    print(\"\\nRunning baseline experiment...\")\n",
    "    baseline_classifier, baseline_le, baseline_accuracy, baseline_report = baseline_experiment(rest_train_data, rest_dev_data, rest_test_data, bert_model, bert_tokenizer)\n",
    "    \n",
    "    print(\"\\nBaseline Experiment Results:\")\n",
    "    print(f\"Accuracy: {baseline_accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(baseline_report)\n",
    "\n",
    "    print(\"\\nBaseline Experiments completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
